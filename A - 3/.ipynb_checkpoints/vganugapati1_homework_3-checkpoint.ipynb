{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "In this homework assignment, you will begin to explore the [SWAN-SF Dataset](https://doi.org/10.7910/DVN/EBCFKM). \n",
    "\n",
    "\n",
    "Below you will find a number of steps that you will be required to complete before you can start the assignment.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Downloading the Data\n",
    "\n",
    "Download individual partitions of the dataset through the following links:\n",
    "- [Partition 1](https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/EBCFKM/BMXYCB)\n",
    "- [Partition 2](https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/EBCFKM/TCRPUD)\n",
    "- [Partition 3](https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/EBCFKM/PTPGQT)\n",
    "- [Partition 4](https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/EBCFKM/FIFLFU)\n",
    "- [Partition 5](https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/EBCFKM/QC2C3X)\n",
    "\n",
    "This assignment will only be using [Partition 1](https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/EBCFKM/BMXYCB), but we will be using more than one by the end of the semster. In later steps, you will need to access the uncompressed files from these partitions, so remember where you put them.\n",
    "\n",
    "A paper describing the construction of the dataset can be found [here](https://doi.org/10.1038/s41597-020-0548-x).\n",
    "\n",
    "---\n",
    "\n",
    "### Dataset Attributes:\n",
    "\n",
    "Each file in the dataset contains the following attributes as a single variate of the multivariate timeseries sample. \n",
    "\n",
    "|              |                  |             |\n",
    "|--------------|------------------|-------------|\n",
    "| 1. Timestamp | 2. TOTUSJH       | 3. TOTBSQ   |\t\n",
    "| 4. TOTPOT\t   | 5. TOTUSJZ       | 6. ABSNJZH  |\t\n",
    "| 7. SAVNCPP   | 8. USFLUX        | 9. TOTFZ\t|\n",
    "| 10. MEANPOT  | 11. EPSZ\t      | 12. MEANSHR |\n",
    "| 13. SHRGT45  | 14. MEANGAM      | 15. MEANGBT |\n",
    "| 16. MEANGBZ  | 17. MEANGBH      | 18. MEANJZH |\n",
    "| 19. TOTFY    | 20. MEANJZD      | 21. MEANALP |\t\n",
    "| 22. TOTFX    | 23. EPSY\t      | 24. EPSX\t|\n",
    "| 25. R_VALUE  | 26. CRVAL1       | 27. CRLN_OBS|\t\n",
    "| 28. CRLT_OBS | 29. CRVAL2       | 30. HC_ANGLE|\t\n",
    "| 31. SPEI     | 32. LAT_MIN      | 33. LON_MIN |\n",
    "| 34. LAT_MAX  | 35. LON_MAX      | 36. QUALITY |\t\n",
    "| 37. BFLARE   | 38. BFLARE_LABEL |\t39. CFLARE  |\t\n",
    "| 39. CFLARE_LABEL | 40. MFLARE | 41. MFLARE_LABEL |\t\n",
    "| 42. XFLARE | 43. XFLARE_LABEL | 44. BFLARE_LOC |\t\n",
    "| 45. BFLARE_LABEL_LOC | 46. CFLARE_LOC | 47. CFLARE_LABEL_LOC |\t\n",
    "| 48. MFLARE_LOC | 49. MFLARE_LABEL_LOC | 50. FLARE_LOC |\t\n",
    "| 51. XFLARE_LABEL_LOC | 52. XR_MAX | 53. XR_QUAL |\t\n",
    "|54. IS_TMFI | | |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Setting up your Environment\n",
    "\n",
    "You will be using the [MVTS Data Toolkit v0.2.6](https://bitbucket.org/gsudmlab/mvtsdata_toolkit) library developed by the [Dataming Lab](https://dmlab.cs.gsu.edu/) at GSU to generate features from this dataset. \n",
    "\n",
    "This tool requires a different version of libraries than were installed when we put Anaconda on your computer at the beginning of the semster.  To get around this, we will be creating an environment specifically for use with this library.\n",
    "\n",
    "--- \n",
    "\n",
    "An environment file was included in the archive given to you for your assignment. Use it to create an conda envronment using the following command\n",
    "\n",
    "    conda env create -f flare_env.yml\n",
    "    \n",
    "Then switch to the newly created envronment using the following command\n",
    "\n",
    "    conda activate flare_env\n",
    "    \n",
    "Then install the [MVTS Data Toolkit v0.2.6](https://bitbucket.org/gsudmlab/mvtsdata_toolkit) library as follows\n",
    "\n",
    "    pip install mvtsdatatoolkit\n",
    "    \n",
    "Assuming you have navigated to where this assignment notebook file is, you will need restart jupyter using your newly created environment\n",
    "\n",
    "    jupyter notebook\n",
    "\n",
    "Anaconda provides this mechanism to allow you to manage multiple environments with different versions of libraries installed.  Each time you wish to start using this environment you will need to activate it again. You can read more about managing environments in Anaconda ([here](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html)).\n",
    "\n",
    "---\n",
    "\n",
    "Documentation of the various methods available through the library can be found ([here](https://dmlab.cs.gsu.edu/docs/mvtsdata_toolkit/)).\n",
    "\n",
    "A tutorial on how to use the library can be found ([here](https://mybinder.org/v2/git/https%3A%2F%2Fbitbucket.org%2Fgsudmlab%2Fmvtsdata_toolkit%2Fsrc%2Fmaster/master?filepath=.%2Fdemo.ipynb)).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Renaming files to fit the library requirements\n",
    "\n",
    "\n",
    "The [MVTS Data Toolkit v0.2.6](https://bitbucket.org/gsudmlab/mvtsdata_toolkit) requires the Multi-Variate Timeseries files to be labled a specific way for it to read them and assign a label to them when processing. Below is a method I have written for you to do this process automatically. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from shutil import copyfile\n",
    "from os.path import isfile, isdir, join, exists \n",
    "from os import makedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renameAndCopy(file_list, source_dir, dest_dir):\n",
    "    if not exists(dest_dir):\n",
    "        makedirs(dest_dir)\n",
    "    for f in file_list:\n",
    "        fileOut = \"lab[{0}]_id[{1}]_st[{2}]_et[{3}].csv\"\n",
    "        idx = f.find('@')\n",
    "        idx4 = f.find('_ar')\n",
    "        idx1 = f.find('_s')\n",
    "        idx2 = f.find('_e')\n",
    "        idx3 = f.find('.csv')\n",
    "        \n",
    "        startTime = f[idx1+2:idx2]\n",
    "        endTime = f[idx2+2:idx3]\n",
    "        idVal = f[idx4+3:idx1]\n",
    "        if(idx == -1):\n",
    "            fileOut = fileOut.format('NF', idVal, startTime, endTime)\n",
    "        else:\n",
    "            label = f[0:1]\n",
    "            fileOut = fileOut.format(label, idVal, startTime, endTime)\n",
    "        copyfile(join(source_dir, f), join(dest_dir, fileOut))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to change the directories to fit your computer, but this is enough to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = [\"partition1\", \"partition2\", \"partition3\", \"partition4\", \"partition5\"]\n",
    "baseSrcDir = \"/data/MVTS/unzipped/{0}/\" #This line needs to be changed to where you have your partitions stored\n",
    "baseDestDir = \"/data/MVTS/processed/{0}/\" #This line needs to be changed to where you want to store the renamed files\n",
    "\n",
    "#This loop processes all of the flaring and nonflaring data from each parition \n",
    "#It copies the files to your processed files directory using the naming convention required by the toolkit library\n",
    "#This only needs to be executed once\n",
    "for p in partitions:\n",
    "    \n",
    "    path_to_partition = baseSrcDir.format(p)\n",
    "    path_to_renamed_files = baseDestDir.format(p)\n",
    "    \n",
    "    flareDir = join(path_to_partition, 'FL')\n",
    "    nonflareDir = join(path_to_partition, 'NF')\n",
    "    \n",
    "    flareFilesList = [f for f in listdir(flareDir) if isfile(join(flareDir, f))]\n",
    "    renameAndCopy(flareFilesList, flareDir, path_to_renamed_files)\n",
    "    nonflareFilesList = [f for f in listdir(nonflareDir) if isfile(join(nonflareDir, f))]\n",
    "    renameAndCopy(nonflareFilesList, nonflareDir, path_to_renamed_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the provided config file (flare_hw_3_config.yml) for the [MVTS Data Toolkit v0.2.6](https://bitbucket.org/gsudmlab/mvtsdata_toolkit) library to read MVTS Parameters 2 through 25 of the dataset above. \n",
    "\n",
    "You will need to configure the FeatureExtractor object of the library and use it to calculate the features from the time series of these parameters in [Partition 1](https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/EBCFKM/BMXYCB) of the dataset. \n",
    "\n",
    "**Note:** The provided config file has a directory in it that lists where to look for the data. You need to edit this to match your directory structure.  \n",
    "\n",
    "---\n",
    "\n",
    "Save the extracted features to a CSV file in some location so you can use them at a later time.  The rest of the assignment requires these features as input.  \n",
    "\n",
    "A useful method to save with is the [pandas.to_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html) method.\n",
    "\n",
    "**Note:** Because of how slow this method is, use the \"first_k=50\" parameter for the method calls and continue by writing code to store this data as though you completed processing the entire partition. I will provide a link below for an already completed dataset for you to use on the remainder of the assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvtsdatatoolkit.features.feature_extractor import FeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Place your answer here, maybe even add a few more cells to break up your work into parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 (10 points)\n",
    "\n",
    "Now that you have saved the extracted features to a csv file, you will load that data into a Pandas DataFrame using the [pandas.read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) method.  \n",
    "\n",
    "**Note:** To help alleviate the need to compute all the features yourself, I have provided an already computed file ([here](http://dmlab.cs.gsu.edu/solar/data/partition1ExtractedFeatures.csv)).\n",
    "\n",
    "Using this dataframe object, you should perform the simple min/max 0-1 normalization on the data. Once this is done, you should save this normalized data as a new csv file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mvtsdatatoolkit.normalizing import normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Place your answer here, maybe even add a few more cells to break up your work into parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 (20 points)\n",
    "\n",
    "Using the normalized data from question 2, perform analysis of the various features.  Find the features that have NULL/NAN values and drop the feature if more than 1% of the entries have null/nan values. For the rest, drop the specific entry that has the null/nan values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mvtsdatatoolkit.data_analysis.extracted_features_analysis import ExtractedFeaturesAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Place your answer here, maybe even add a few more cells to break up your work into parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 (20 points)\n",
    "\n",
    "Using the normalized and cleaned data from question 3, you now need to perform feature selection on the dataset and take the 20 most useful features for classification. For now, we will utilize all the different labels in our evaluation of features (i.e. NF, B, C, M, X).  To perform the ranking you will utilize the ANOVA F-Value to select the top 20 features and save them to a new file.\n",
    "\n",
    "Some methods that will be useful for this operation are the methods through [scikit-learn Univariate Feature Selection](https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection), and the [scikit-learn f_classif](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html#sklearn.feature_selection.f_classif) method.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Place your answer here, maybe even add a few more cells to break up your work into parts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
